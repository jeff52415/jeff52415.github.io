---
layout: default
---

<div class="home" role="main">
  <header class="profile-header" role="banner">
    <div class="terminal" role="region" aria-label="Profile Information">
      <div class="terminal-header" role="heading" aria-level="2">
        <span class="terminal-button" aria-hidden="true"></span>
        <span class="terminal-button" aria-hidden="true"></span>
        <span class="terminal-button" aria-hidden="true"></span>
        <span class="terminal-title">profile.sh</span>
      </div>
      <div class="terminal-body">
        <p class="command">$ whoami</p>
        <div class="output">
          <h1>Chening Yang</h1>
          <h2>Director of AI Research & Development</h2>
          <p class="mission">Pioneering the future of AI through innovative research and practical applications</p>
        </div>
        <p class="command">$ cat about.txt</p>
        <div class="output profile-description">
          <p>Driving innovation in AI with expertise in:</p>
          <ul class="expertise-list" role="list">
            <li role="listitem"><span class="prompt" aria-hidden="true">></span> Visually Rich Document Understanding (VRDU)</li>
            <li role="listitem"><span class="prompt" aria-hidden="true">></span> Agentic Retrieval-Augmented Generation (RAG)</li>
            <li role="listitem"><span class="prompt" aria-hidden="true">></span> Leading 40+ R&D professionals</li>
          </ul>
        </div>
        <p class="command">$ _</p>
      </div>
    </div>
  </header>

  <section class="contact-info">
    <h2><i class="fas fa-paper-plane"></i> Let's Connect</h2>
    <div class="terminal" role="region" aria-label="Contact Information">
      <div class="terminal-header">
        <span class="terminal-button"></span>
        <span class="terminal-button"></span>
        <span class="terminal-button"></span>
        <span class="terminal-title">contact_info.sh</span>
      </div>
      <div class="terminal-body">
        <p class="command">$ cat contact_details.txt</p>
        <div class="output">
          <div class="contact-grid">
            <div class="contact-item">
              <a href="mailto:jeff52415@gmail.com" class="contact-link" aria-label="Email: jeff52415@gmail.com">
                <i class="fas fa-envelope" aria-hidden="true"></i>
                <span>jeff52415@gmail.com</span>
              </a>
            </div>
            <div class="contact-item">
              <a href="https://linkedin.com/in/chening-yang-6ab362a5" class="contact-link" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn Profile">
                <i class="fab fa-linkedin"></i>
                <span>LinkedIn Profile</span>
              </a>
            </div>
            <div class="contact-item">
              <a href="https://github.com/jeff52415" class="contact-link" target="_blank" rel="noopener noreferrer" aria-label="GitHub Projects">
                <i class="fab fa-github"></i>
                <span>GitHub Projects</span>
              </a>
            </div>
            <div class="contact-item">
              <div class="location">
                <i class="fas fa-map-marker-alt"></i>
                <span>Taipei, Tokyo</span>
              </div>
            </div>
          </div>
        </div>
        <p class="command">$ _</p>
      </div>
    </div>
  </section>

  <section class="skills">
    <h2><i class="fas fa-tools"></i> Core Competencies</h2>
    <div class="skill-grid">
      <div class="skill-item">
        <h3><i class="fas fa-brain"></i>&nbsp; AI Research & Development</h3>
        <div class="skill-content">
          <p>Leading innovation in:</p>
          <ul class="skill-list">
            <li><span class="proficiency expert">Specialist</span> Large Language Models (LLMs)</li>
            <li><span class="proficiency expert">Master</span> Document Understanding</li>
            <li><span class="proficiency advanced">Proficient</span> Multi-Modal AI Systems</li>
          </ul>
        </div>
      </div>
      <div class="skill-item">
        <h3><i class="fas fa-project-diagram"></i>&nbsp; Technical Leadership</h3>
        <div class="skill-content">
          <p>Driving excellence through:</p>
          <ul class="skill-list">
            <li><span class="proficiency expert">Lead</span> Cross-functional R&D Team Management</li>
            <li><span class="proficiency expert">Principal</span> Project Architecture</li>
            <li><span class="proficiency advanced">Strategic</span> Roadmap Planning</li>
          </ul>
        </div>
      </div>
      <div class="skill-item">
        <h3><i class="fas fa-code-branch"></i>&nbsp; System Architecture</h3>
        <div class="skill-content">
          <p>Specialized in:</p>
          <ul class="skill-list">
            <li><span class="proficiency expert">Master</span> Agentic RAG Systems</li>
            <li><span class="proficiency advanced">Core</span> Distributed Systems</li>
            <li><span class="proficiency advanced">Proficient</span> Cloud Infrastructure</li>
          </ul>
        </div>
      </div>
      <div class="skill-item">
        <h3><i class="fas fa-cogs"></i>&nbsp; Product Development</h3>
        <div class="skill-content">
          <p>End-to-end expertise in:</p>
          <ul class="skill-list">
            <li><span class="proficiency expert">Lead</span> AI Product Strategy</li>
            <li><span class="proficiency advanced">Advanced</span> Solution Design</li>
            <li><span class="proficiency advanced">Skilled</span> Production Deployment</li>
          </ul>
        </div>
      </div>
    </div>
  </section>

  <section class="research-landscape">
    <h2><i class="fas fa-microscope"></i> Research Timeline</h2>
    <div class="timeline-item">
      <h3>2024 H2</h3>
      <div class="research-item">
        <h4><span class="topic">LLM / Embedding Model Serving</span></h4>
        <p>Researched scalable and efficient methods for serving LLMs and embedding models in production environments to support high-throughput applications.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: Text Generation Inference, vLLM, SGLang, Text Embeddings Inference.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">Multi-Agent RAG</span></h4>
        <p>Explored advanced agentic RAG frameworks for scalable tool usage, memory organization, query management, reflection, reasoning, and execution.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: MetaGPT, AutoGen.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">LLM Architecture</span></h4>
        <p>Conducted a comprehensive survey of fundamental structures and design principles behind various LLM models.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: DeepSeek, LLaMA, Owen, Titans.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">Graph-Based RAG</span></h4>
        <p>Researched graph-based retrieval paradigms and algorithms to enhance retrieval performance, exploring single- and multi-graph architectures, as well as layout-based and domain-entity graphs.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: Microsoft GraphRAG, Neo4j.</p>
      </div>
    </div>

    <div class="timeline-item">
      <h3>2024 H1</h3>
      <div class="research-item">
        <h4><span class="topic">Document Structurization</span></h4>
        <p>Built an end-to-end solution to transform unstructured or semi-structured data into structured formats easily interpretable by LLMs. Examples include converting Excel/PDF files into JSON or Markdown.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: Transformers, Gradio, Docling, Unstructured-IO, LlamaParse, Azure AI Document Intelligence.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">LLM Reasoning and Acting</span></h4>
        <p>Researched various LLM reasoning schemas with Human-in-the-loop approaches, including Chain-of-Thought (CoT), Tree-of-Thought (ToT), Self-Consistency, ReAct, and Retrieval-Augmented Workflow Optimization (ReWOO).</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: LangGraph, LangSmith, LlamaIndex, Haystack.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">Retrieval-Augmented Generation</span></h4>
        <p>Developed an LLM-powered chatbot utilizing Retrieval-Augmented Generation (RAG) to effectively leverage user-provided data for generating accurate and contextually grounded answers.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: Elasticsearch, Milvus, Kotaemon.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">Trustworthy LLM</span></h4>
        <p>Investigated methods to reduce LLM hallucinations and enhance knowledge grounding for trustworthy AI outputs.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: TruLens, Ragas, DeepEval.</p>
      </div>
    </div>

    <div class="timeline-item">
      <h3>2023 H2</h3>
      <div class="research-item">
        <h4><span class="topic">Tech Stack Management</span></h4>
        <p>Investigated effective approaches to organize and manage technical assets for streamlined workflows.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: Hugging Face Hub, Hugging Face Spaces.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">Table Detection and Recognition</span></h4>
        <p>Researched methodologies for extracting table information, exploring specialized models for table detection and recognition.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: DETR, TATR.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">ETL Pipeline</span></h4>
        <p>Designed an efficient ETL pipeline for performance tracking and continuous improvement of workflows.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: Apache Airflow, Docker Swarm, Kubernetes.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">LLM Training</span></h4>
        <p>Researched techniques for training and serving large language models (LLMs), covering pretraining, supervised training, preference alignment (RLHF), quantization, and low-rank adaptation methods.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: PEFT, OpenAI, bitsandbytes, W&B, TorchTune, LangChain, Accelerate.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">Multi-Label Classification</span></h4>
        <p>Researched lightweight CNN and ViT architectures to develop efficient multi-label classifiers for diverse datasets and tasks.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: Dino, PyTorch Image Models.</p>
      </div>
    </div>

    <div class="timeline-item">
      <h3>2023 H1</h3>
      <div class="research-item">
        <h4><span class="topic">Lightweight Multimodal Architecture</span></h4>
        <p>Developed a CPU-compatible transformer-based architecture for information extraction, integrating image and text inputs while emphasizing spatial information learning. Achieved state-of-the-art performance among lightweight transformer models. Published two accepted papers at ICDAR 2024.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: Transformers, FAISS.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">Text Recognition</span></h4>
        <p>Researched advanced OCR architectures, focusing on transformer-based encoder-decoder models with innovative image synthesis and augmentation techniques.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: PyTorch Lightning, Albumentations.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">Training Strategies</span></h4>
        <p>Experimented with training techniques for CNN and transformer-based architectures, including Stochastic Depth, Teacher-Student Knowledge Distillation, Label Smoothing, and learning rate warm-up strategies.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: PyTorch Image Models (timm).</p>
      </div>
    </div>

    <div class="timeline-item">
      <h3>2022 H2</h3>
      <div class="research-item">
        <h4><span class="topic">Document Object Detection</span></h4>
        <p>Experimented with anchor-based and anchor-free architectures for document object extraction.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: Ultralytics, MMDetection.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">Sentence Embedding</span></h4>
        <p>Researched lightweight multilingual sentence embedding techniques for improved efficiency and scalability.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: Sentence Transformers (SBERT).</p>
      </div>
    </div>

    <div class="timeline-item">
      <h3>2022 H1</h3>
      <div class="research-item">
        <h4><span class="topic">Image Registration</span></h4>
        <p>Researched local image feature matching using OpenCV-based methods (e.g., SIFT, ORB) and deep learning solutions (e.g., LoFTR).</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: OpenCV, Kornia.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">Cloud Deployment</span></h4>
        <p>Deployed an Intelligent Document Processing (IDP) pipeline on AWS, experimenting with distributed system designs for scalability and performance.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: Docker, AWS Services, Seldon, Celery, FastAPI, Uvicorn.</p>
      </div>
    </div>

    <div class="timeline-item">
      <h3>2021 H2</h3>
      <div class="research-item">
        <h4><span class="topic">Key-Value Pair Extraction</span></h4>
        <p>Explored transformer-based architectures for key-value extraction, focusing on BERT-based models and their variations.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: PyTorch, Hugging Face Transformers.</p>
      </div>
    </div>

    <div class="timeline-item">
      <h3>2021 H1</h3>
      <div class="research-item">
        <h4><span class="topic">Model Compression</span></h4>
        <p>Researched Knowledge Distillation and Post-Training Quantization (PTQ) for lightweight, high-performance models.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: OpenVINO, TorchScript.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">Model Serving</span></h4>
        <p>Investigated efficient model serving methods using ONNX and TensorRT for optimized deployment.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: TensorRT, ONNX.</p>
      </div>
    </div>

    <div class="timeline-item">
      <h3>2020 H2</h3>
      <div class="research-item">
        <h4><span class="topic">Key-Value Pair Extraction</span></h4>
        <p>Applied DGCNN and Residual Gated Graph ConvNets for key-value extraction. Enhanced spatial learning with CenterNET and explored metric learning techniques for embedding and clustering.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: DGL, PyTorch Hub, pytorch-metric-learning.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">Sentence Segmentation</span></h4>
        <p>Developed strategies using Named Entity Recognition (NER) to segment sentences into meaningful pieces. Implemented GRU/LSTM with CRF loss for tokenization and tagging.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: pytorch-crf.</p>
      </div>
    </div>

    <div class="timeline-item">
      <h3>2020 H1</h3>
      <div class="research-item">
        <h4><span class="topic">Node Classification</span></h4>
        <p>Investigated graph construction and applied Graph Attention Networks (GANs) for document node classification tasks.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: DGL.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">Document Embedding</span></h4>
        <p>Researched graph-based solutions, including Graph Convolutional Networks (GCNs), for effective document embedding and representation.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: DGL.</p>
      </div>
    </div>
    
    <div class="timeline-item">
      <h3>2019 H2</h3>
      <div class="research-item">
        <h4><span class="topic">Text Detection</span></h4>
        <p>Researched CNN backbones and loss functions for encoder-decoder architectures in text detection.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: Sagemaker, S3, TensorFlow, imgaug.</p>
      </div>
      <div class="research-item">
        <h4><span class="topic">Text Recognition (OCR)</span></h4>
        <p>Improved CRNN+CTC architecture for unlimited-length OCR decoding.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: Sagemaker, S3, PyTorch.</p>
      </div>
    </div>    
    <div class="timeline-item">
      <h3>2019 H1</h3>
      <div class="research-item">
        <h4><span class="topic">Person Re-Identification</span></h4>
        <p>Researched face detection and recognition solutions integrated with human re-identification architectures to develop a surveillance application.</p>
        <p class="tech-stack"><strong>Tech Stack</strong>: FaceNet, R-CNN, DeepFace, MTCNN, SSD.</p>
      </div>
    </div>
  </section>
</div>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
<link rel="stylesheet" href="{{ '/style.css' | relative_url }}">